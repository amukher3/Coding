{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Abhishek Mukherjee\n",
    "Email: abhi0787@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/amukher3/Downloads/screening_exercise_orders_v201810.csv\")\n",
    "\n",
    "df['order_count'] = df.customer_id.map(df.customer_id.value_counts())\n",
    "\n",
    "df_prime=[]\n",
    "most_recent_dates=[]\n",
    "gender=[]\n",
    "order_count=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Part A ###################################\n",
    "\n",
    "\n",
    "#Customer IDs\n",
    "Unique_ids=list(set(df['customer_id']))\n",
    "\n",
    "for i in range(len(Unique_ids)):\n",
    "    \n",
    "   df_prime= df.loc[df['customer_id']==Unique_ids[i]]\n",
    "\n",
    "   #df_prime=df.loc['customer_id',:]= Unique_ids[i]    \n",
    "   \n",
    "   df_prime.loc[:,'date'] = pd.to_datetime(df_prime.loc[:,'date'])\n",
    "   \n",
    "   #most recent order date\n",
    "   most_recent_dates.append(str(df_prime['date'].max()))\n",
    "   \n",
    "   df_Prime_to_list=df_prime['gender'].values[0]\n",
    "   \n",
    "   #Gender\n",
    "   gender.append(df_Prime_to_list)\n",
    "   \n",
    "   #Order count\n",
    "   tempOrderCount=df_prime['order_count'].values[0]\n",
    "   order_count.append(tempOrderCount)\n",
    "   \n",
    "#Final DataFrame\n",
    "Data_Frame=pd.DataFrame({'customer_id':Unique_ids,\n",
    "                            'gender':gender,\n",
    "                            'most_recent_order_date':most_recent_dates,\n",
    "                            'order_count': order_count})\n",
    "    \n",
    "#sorting the data frame\n",
    "Data_Frame=Data_Frame.sort_values('customer_id')    \n",
    "\n",
    "#Displaying the first 10 rows\n",
    "Data_Frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Part B ########################################\n",
    "\n",
    "%matplotlib inline\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Changing the string to date-time object(Time stamps)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#Sorting the Time Stamps in ascending order\n",
    "df=df.sort_values('date')\n",
    "\n",
    "OrderSum=[]\n",
    "#total number of secs in a week\n",
    "NumSecWeek=604800\n",
    "stPos=0\n",
    "temp=0\n",
    "tempPrime=0\n",
    "\n",
    "for i in range(len(df['date'])-1):\n",
    "    \n",
    "    TimeDiff= df['date'][stPos]-df['date'][i+1]\n",
    "    TimeDiffSecs= TimeDiff/ timedelta(seconds=1)\n",
    "    \n",
    "    if abs(TimeDiffSecs)<=NumSecWeek:\n",
    "        temp=df['order_count'][i]\n",
    "        tempPrime=temp+tempPrime\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        OrderSum.append(tempPrime) \n",
    "        \n",
    "        stPos=i        \n",
    "        tempPrime=0\n",
    "       \n",
    "plt.plot(OrderSum) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Part C ####################################\n",
    "\n",
    "import statistics\n",
    "\n",
    "#For gender '0'\n",
    "df_gender= df.loc[df['gender']==0]\n",
    "\n",
    "GenVals=df_gender['value'].tolist()\n",
    "meanVal_0=statistics.mean(GenVals)\n",
    "\n",
    "\n",
    "#For gender '1'\n",
    "df_gender= df.loc[df['gender']==1]\n",
    "\n",
    "GenVals=df_gender['value'].tolist()\n",
    "meanVal_1=statistics.mean(GenVals)\n",
    "\n",
    "\n",
    "#Comment --- No significant difference between the mean order values betweent the genders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meanVal_0)\n",
    "print(meanVal_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Part D #######################################  \n",
    "\n",
    "#Assumptions:\n",
    "\n",
    "#For getting a single prediciton for every customer I have used the first of \n",
    "# the predicted gender from the set of predictions for a particular Customer ID \n",
    "# For example, if there are six different predictions for a particular customer \n",
    "# since a particualar customer might have purchased from the store six different times\n",
    "# he would have six different predicted genders. \n",
    "# I have used the first from those predictions. \n",
    "\n",
    "\n",
    "#Getting a single prediction for every customer\n",
    "PredictedGender=[]\n",
    "\n",
    "for i in range(len(Unique_ids)):\n",
    "    \n",
    "    df_predicted_gender= df.loc[df['customer_id']==Unique_ids[i]]\n",
    "    PredictedGender.append(df_predicted_gender['predicted_gender'].values[0])\n",
    "    \n",
    "#Generating confusion matrix    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#ConfusionMatrix\n",
    "cm = confusion_matrix(gender,PredictedGender) \n",
    "   \n",
    "#TruePositive\n",
    "TP=cm[0][0]\n",
    "\n",
    "#TrueNegative\n",
    "TN=cm[1][1]\n",
    "\n",
    "#FalseNegative\n",
    "FN=cm[0][1]\n",
    "\n",
    "#FalsePositive\n",
    "FP=cm[1][0]\n",
    "\n",
    "\n",
    "Accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "Recall=TP/(TP+FN)\n",
    "\n",
    "Precision=TP/(TP+FP)\n",
    "\n",
    "F_measure=(2*Recall*Precision)/(Recall+Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6468118901747221\n",
      "0.4967097798956206\n",
      "0.709792477302205\n",
      "0.5844346549192364\n"
     ]
    }
   ],
   "source": [
    "print(Accuracy)\n",
    "print(Recall)\n",
    "print(Precision)\n",
    "print(F_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the confusion matrix we can see that it has a better Precision than Recall\n",
    " This indicates that we miss a lot of positive examples(high FN) but we are \n",
    " better in our precision i.e the ones we predict as positives are indeed \n",
    " positives which indicates a low FP.\n",
    " Actually, both Precision and Recall are not that high as can be seen from the\n",
    " number of high FP and high FN. \n",
    " The model that predits the gender seems to produce a high amount of FPs and \n",
    " FNs which doesn't make it a good classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################### Part E #####################################\n",
    "\n",
    "Very recently I had used a techinique called xgBoost for completing a competitive challenge. The data was kind of unorthodox because it had around 20,000 features and just 500 observations this resulted in a very 'fat' design matrix. All of the observations were binary in nature i.e 0 and 1. \n",
    "This was a bit of a caveat because this restrained me from using conventional dimensionality reduction tools such as PCA.I had to look for DR techniques which could reduce the dimensionality of the features having binary observation.On top of that the tree boosting techniques have been seen to give good performace in comparison to normal ensemble classifier like Random Forest. One could reduce the feature set with binary observations into smaller set with the help of feature boosting techniques. \n",
    "I had observed xgBoost doing relatively well in kaggle challenges with a similar type of data setup. Hence, this was my go-to solution whenever I encountered datasets with similar (n,p) values. And not surprisingly it did decently on the provided datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
